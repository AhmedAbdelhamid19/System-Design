- A distributed system is:
	○ many machines working together as if they are one system.
	○ Multiple computers (servers) connected over a network, working together to behave like one powerful system.
- why do we even need distributed systems?
	○ too many users, Millions open the app at the same moment. One server cannot handle millions of requests per second.
	○ Too much data (petabytes of data)
	○ Need for high reliability, If your only server dies, your whole business dies. Companies need systems that continue working even when hardware fails.
	○ Need for fast global access, A user in Egypt, another in Germany, another in the USA. One server cannot give all of them low-latency responses.
- What is the difference between design patterns, software architecture, and system design?
	○ Design Pattern:
		- Concerned with how classes and objects interact inside a single application, Focuses on writing clean, reusable, testable code
		- Solves recurring code level problems, Operates at small scale inside one codebase and usually one process
		- Does not decide how the whole system is structured, only how parts of the code cooperate
		- for example choose repository pattern to separate database access from business logic …etc, so you Improve code quality and maintainability, not scalability of the system.
	○ Software Architecture:
		- Concerned with how the application is structured internally, and define layers.
		- Solves maintainability and evolution problems as the codebase grows, and operates at medium scale inside one application or service.
		- for example choose 3 Tier layer (frontend, backend, database)
	○ System Design:
		- Concerned with designing the entire system that runs across many machines, includes servers, networks, databases, caches, load balancers, and external services
		- Operates at very large scale with millions of users and requests, it's a problem solving process, not a fixed structure.
		- for example, designing an Instagram like backend:
			□ Load balancers to distribute traffic, and Caching to reduce database load.
			□ Databases and replication strategies, CDN for images and videos, Microservices for independent scaling.
- explain the following?
	○ Scalability: (how to handle more workload)
		- vertical scalability (scale up): upgrade the server to more powerful server (more ram …etc.)
		- horizontal scalability (scale out): Add more machines when load increases
	○ Elasticity: (focus on both directions, increase and decrease based on traffic)
		- Resources automatically grow and shrink based on traffic.
		- cloud providers like AWS support these.
	○ Replication: 
		- Data is copied across multiple machines to improve availability and fault tolerance. There are different replication models such as master slave and others.
		- Synchronous Replication (with writes): Every write operation must be applied to all replicas at the same time before the system acknowledges success to the client 
			□ strong consistency, less scalability, less availability, more latency, slower writes but no data loss in case of primary failure
		- Asynchronous Replication (with writes): The primary node write the data first then immediately acknowledges writes to the client without waiting for replicas to confirm. after that Replicas are updated in the background 
			□ faster writes, more scalability, eventual consistency, more availability
			□ less latency but potential data loss if for any reason the replica wasn't update with new value then it will have the old value for ever
	○ Fault Tolerance: 
		- System keeps working even if one machine dies
	○ SPOF (single point of failure)
		- A component (server, database, network device) whose failure will bring down the entire system
	○ Redundancy
		- Having duplicate components so that if one fails, another can take over (like backup)
	○ Availability: 
		- The system is able to serve users most of the time and Users can access the system successfully when they try, even when server fail
	○ Consistency: 
		- All machines see the same data.
		- Strong consistency: all servers see the new value immediately, like bank balance or booking ticket.
		- Eventual consistency: servers may show old data briefly (for short time), like post/comment update/delete in facebook, sometimes it's acceptable depending on the business.
	○ Partitioning: 
		- splitting data into logical parts, which can be within the same server or across multiple servers depending on the system.
	○ Sharding: 
		- Splitting data across many machines
	○ Latency: 
		- Delay to respond
	○ reliability: 
		- Reliability is the system’s ability to run correctly over time, tolerating failures without data loss or incorrect behavior (do what's supposed to do) 
	○ Coordination:
		- how multiple machines agree on one decision so the system does not behave incorrectly?
		- Imagine there is one last airplane seat, and there's request from egypt and another from USA and each go to different servers, then how your distributed system handle these situation?
	○ cluster
		- means group of separate computers or servers that work together as one system.
- what's the difference between fault tolerance and availability?
	○ they are connected but are not the same.
	○ system may have High availability but low fault tolerance
		- you have powerful server with no backups, so your system available unless it fails
		- availability touches with latency, load and responsiveness, for example we made our system available 99% percent of the time or 99.99% percent .
	○ system may have High fault tolerance but low availability
		- A system might survive failures but take a long time to recover or respond slowly
		- fault tolerance means when part of system dies, then who should your system recover quickly and make your data in safe hand.
- what's master-slave in systems or databases, how it's useful?
	○ It is a replication model where you have main node/nodes called the master and one or more secondary nodes called slaves.
	○ The master is the only one who receives write operations, The slaves only receive read operations and copies of the master data.
	○ A write request goes to the master, then The master updates its data, then:
		- if strong consistency, The master sends the new data to the slaves so they become copies of it then response to the user, now slaves ready to read operations
		- if eventually consistency, the master response to the user then The master sends the new data to the slaves so they become copies of it, now slaves ready to read operations
	○ reduce load on the master by sending read operations to slaves, very useful in heavy/intensive read systems.
	○ can increase availability since slaves can take over when the master fails.
- what's the difference between replica, redundancy, partitioning, sharding?
	○ Replication (copy data) 
		- focuses on data and means copying data from one server to other servers.
	○ Redundancy (copy component/resource …) 
		- means having extra resources available so the system keeps working if something fails (servers, databases (backup), networks, power supplies, disks).
	○ Partitioning 
		- means splitting one database table into logical parts inside the same database server.
		- horizontal partitioning
			□ for example the able order is split into partition 2023, 2024 …
			□ organize and speed up large tables, inside same server like single big notebook divided into sections
		- vertical partitioning
			□ split the columns itself in very big table that consist of multiple columns and connect them by FK
	○ sharding
		- means splitting the data across multiple servers or multiple database instances, focuses on different machines.
		- for example, user A to M lives on Server1, user N to Z lives on server2, like instead of one notebook, you make multiple notebook each7 for some sort of data
- what's the problems that may appears with sharding?
	○ joins, because you will need to make network calls so it slow the query and make it complex (cross sharding queries).
- explain ACID in databases
	○ ensure a transaction is safe and reliable, A transaction is a group of operations that act like one unit 
		- like transfer money from one account to another (subtract from account A and add to account B).
	○ A for Atomicity
		- Atomicity means all or nothing, Either the entire transaction happens or none of it happens, no partial changes
		- If the system crashes after subtracting money from account A but before adding to account B, then the database rolls back the transaction
	○ C for Consistency (definition of consistency here differ from system design)
		- Consistency means the data must move from one valid state to another valid state based on rules, constraints (FK, unique …) and business logic.
		- for example bank account balance cannot become negative, or FK mustn't refer to id that doesn't, or redundant value in unique columns …etc.
	○ I for Isolation
		- Isolation means your transaction should not see the unfinished work of another transaction.
		- Transactions run as if they are happening alone, even if many people are using the system at once.
		- isolation protect you from concurrency problems like dirty reads …etc.
	○ D for Durability
		- Durability means once a transaction is committed, the data will not be lost, even if the system crashes.
- what serverless means?
	○ means you don’t manage servers.
	○ Serverless is a cloud execution model where you run code without provisioning, configuring, or managing servers.
	○ The cloud provider (AWS, Azure, GCP) handles scaling, infrastructure, failures …etc.
- what's CDN (Content Delivery Network)?
	○ CDN is a network of servers around the world that cache (store) your static content (images, videos, CSS, JS) close to users.
	○ CDNs do not execute code or store dynamic data like backend or database servers. They only cache and serve static content (images, videos, CSS, JS) close to users..
	○ speed up loading time and reduce traffic on your main server and reduce latency and make your application global
	○ for example if User from Germany wants image logo.png so CDN checks nearest server, If cached then returns immediately (super-fast), if not then fetches from your origin server, caches it, returns it, so Next German user gets it instantly from local CDN node
	○ one of most popular CDNs is Cloudflare.
- what's DNS (Domain name system)?
	○ DNS is the internet’s phonebook, that converts a domain name to IP address (to make it human friendly).
	○ when you type facebook.com then the browser ask DNS to give him the IP address, then the browser use IP to connect to the server, and website loads
	○ Without DNS, the internet would look like this https://142.250.190.14/home instead of google.com
- list some challenges should be handled with caching?
	○ expiry time should be handled carefully.
	○ when the cache be updated.
	○ caching in horizontal scaling.
	○ complexity and development time and effort
- what's the difference between replica and backup?
	○ replica:
		- A replica is a live copy of your database or server that is continuously updated to reflect changes from the primary source.
		- may be synchronous (strong consistency) or asynchronous (eventual consistency)
		- If the primary database goes down, the replica can often take over immediately.
		- you may have master node to write, and slaves nodes (replicas) for read (there are other types other than master-slave model)
		- sensitive to programmer error:
			□ if programmer delete by default rows of table or dropped a table, then replicas also affected
	○ backup
		- A backup is a point-in-time copy of your data stored separately, usually not live.
		- Mainly for data recovery after data loss, corruption, or accidental deletion.
		- Backups are often taken periodically (daily, hourly, etc.).
		- You restore from a backup when needed; it’s not automatically in sync.
		- not sensitive to programmer error if the backup was taken before the error occurred, so if programmer delete by default rows of table or dropped a table, then the backup safe you
- Is a backend API supposed to be stateless or stateful, and why do most modern systems prefer a stateless design?
	○ Backend APIs should be stateless, especially in modern web systems, unless there is a specific case that forces a stateful design.
	○ because When many users hit your backend at the same time, you want any request to be handle by any server (if you scaled horizontally).
	○ if it was stateful (The server keeps the user session or temporary data in its memory), you will consume server resources.
- talk about the process that you will go through it when you vertically scaling?
	○ first look at what we can scale (CPU, RAM, Disk, Network)
		- we should pick what needs to be scaled not scale the entire server
	○ when we use most of resources (near to 100%) of the server
		- A web app may respond very slowly or timeout for users, heavy calculations may freeze the system
		- Applications crash, database queries fail, system becomes very slow
		- All services stop responding, client requests fail, sometimes need a restart
		- Users experience timeouts, slow page loads, streaming services buffer or fail
	○ so you should have threshold so if you exceeded it, then you should think about scaling your app (vertically or horizontally with load balancer)
- if you have the ability to double the resources of the server itself or add another server with same resources what you prefer?
	○ add another server (with load balancer), so we avoid SPOF if one server fail then the other server will take over.
	○ Diminishing returns:
		- after a certain point, adding more resources gives you smaller added performance value related to cost added
	○ adding more resources instead of split to 2 server may little good because you avoid overhead of network if servers talk to each other.
- what's multi-master DB clustering?
	○ multiple DB nodes can accept write, and the changes are replicated to other nodes
	○ pros: High availability, write can happen anywhere (in master node).
	○ cons: conflict should be handled if 2 nodes update the same data.
- what's the difference between latency and availability?
	○ latency means time taken to response, measured by seconds/milliseconds.
	○ availability (able to response) is the of time the system able to response, measured by percent like 99%, 99.99%
	○ availability (able to response) is the of time the system able to response, measured by percent like 99%, 99.99%
- is consistency prevent failures?
	○ Strong consistency does NOT prevent failures, system may reject, may block writes, but it focuses on returning most recent data only.
- don't say 'I choose AP because it is scalable', but say 'I choose AP because showing stale data for 5 seconds is acceptable for this product'
- is load balancer solve CAP problem?
	○ Load balancers do not solve CAP, it's for routing traffic.
	○ it improves availability mainly by handling failures and distributing requests, traffic.
	○ CAP is at the data layer, and load balancer at routing layer.
- do you prefer your system to be AP or CP?
	○ It depends on business requirements and acceptable behavior during a partition.
- Can we have CA in distributed systems?
	○ No in distributed systems
	○ You can have CA only when there is no network partition. In the presence of a partition, CA is impossible, which is what CAP actually states.
- what's the difference between relational DB and NoSQL DB?
	○ relational DB focuses on correctness and structure first, NoSQL focuses on scaling and flexibility.
	○ sometimes hybrid system used, so some features deal with NoSQL, other deal with relational DB.
	○ relational
		- correctness, transactions (ACID), integrity.
		- data split into many tables connected by relationships, this avoid duplication but requires joins (joins become expensive at scale).
		- add new columns requires migration, change schema (modern relational databases support online schema changes without full table locks), lock table, and risk in production.
		- you get right data, no contradictions.
		- you can make column of type JSON and store nested data (but don't powerful like NoSQL database)
	○ NoSQL (not only sql)
		- scalability, horizontal scale, flexibility (schemaless). 
		- data which stored together, used together, you build it based on 'how will i access this data'.
		- data is stored as document structures similar to JSON, using internal binary formats optimized for storage and access.
		- you don't need to make joins (you can store nested data), support fast read, but cost duplication.
		- instead of storing data in seperated tables, we store it as nested data (store devices information inside user collection).
  - should have implicit schema to reduce work and overhead you make, means avoiding random keys and random nested data …etc. to ease it to you when you work with backend (deserialization).
- why NoSQL scalable / what's more scalable NoSQL or relational DB?
	○ NoSQL systems are generally easier to scale horizontally than traditional relational databases.
	○ NoSQL is designed to scale horizontally by default, relational DB is designed to be correct by default.
	○ NoSQL avoid joins, because it by default store related data together, one request hits one server, it avoid overhead specially with joins with sharded data.
- what's more high available NoSQL or relational DB?
	○ NoSQL prioritizes availability, relation DB support strong consistency (remember CAP theorem)
	○ NoSQL is spread to different servers (what supposed to be), and many nodes active at the same time, if one node dies other continue serving.
- what problems may appears with duplication with NoSQL databases?
	○ the core problem is keeping duplicated data consistent (up-to-date).
	○ for example if 'price' stored in product document and order document …., and 'price' is updated, the challenge is how to update the price in all instances in all documents.
	○ updates are often propagated asynchronously, which commonly results in eventual consistency where users may temporarily read stale data.
	○ there're a lot of ways to update the data: 
		- background propagation (send event to workers to updated related parts), immutable data (old data never update), read repair (on read detect stale data) …etc.
- what's Redis, what problem Redis solves?
	○ database access is slow compared to memory, some data is read and written very frequently
	○ Redis keep data in RAM, so queries become very fast (micro seconds), it's in memory key value data store
	○ it used to cache 
		- database queries
		- user sessions (if user made request, it check session in redis, if exist then user authenticated)
		- API rate limit (if user made 100 request, the counter stored in redis) …etc.
	○ Redis is not main database, because RAM is expensive, and data can be lost if not persisted.
- what's elastic search, what problem it solve?
	○ relational databases can search text using indexes, but they are not optimized for large scale full text search, relevance ranking, and complex text queries, which leads to poor performance at scale.
	○ Elasticsearch stores its own copy of data, but it is usually not the source of truth; the primary data lives in another database.
- what's Client side IndexedDB, what problem it solves?
	○ IndexedDB is used to store large amounts of structured data on the client side, enabling offline support, faster access, and reduced network requests.
	○ it's browser built in data base, persistent, asynchronous, used for offline support, caching API responses …etc.
	○ limited to browsers only, and user can clear it, and not shared across devices.
- list some types of NoSQL database.
	○ key value
		- key is unique identifier, and value is blob of data.
			□ key here like PK in relation database, that from it you ger the row, but here from key you get the value of that document
		- basic operations: get(key), set(key, value), delete(key)
		- hash function used to get the location of the data in time near to O(1), it's Extremely fast for lookups by key.
		- Value can be anything (string, JSON, binary), but the database cannot query inside it (unless the engine has special features).
		- the value is opaque to the database (database does not understand the structure).
		- Redis, DynamoDB are popular key value databases 
	○ document
		- A database that stores data as documents, usually in JSON-like format (MongoDB uses BSON, which is binary JSON), Different documents in the same collection can have different fields.
		- Each document is a self-contained unit of data. It can have nested objects, arrays, and varying fields.
		- Can query by indexed fields, including nested keys, and supports secondary indexes and complex queries.
		- Examples: MongoDB
	○ wide column
	○ graph
- NoSQL Replication & Consistency (R, W, RF)
	○ RF (Replication Factor): Number of nodes holding a copy of the data.
	○ W (Write quorum): Minimum nodes that must acknowledge a write.
	○ R (Read quorum): Minimum nodes that must respond to a read.   
	○ for example if you have 5 DB all for read and write, then if you made write to 3 DB and read from 3 DB then you guarantee to take latest data in read query (with read, check overhead).
	○ it's another solution other than write to all node and read from 1 node, here we make R + W > RF, so we write to less node and read from more node and make another overhead to take latest data.
	○ you can make it strong consistency if R + W > RF, or not strong consistency if R + W <= RF (some time you may accept stale data, another you are lucky and get most recent data)
- what's the different between NoSQL and use JSON column in relation database?
	○ relation DB: 
		- You still have tables and columns, but one column can store dynamic JSON data.
		- Horizontal scaling (sharding) is possible, but becomes complex due to joins, cross shard queries, and distributed transactions.
		- some DBMS allow you to query inside JSON but it's not as rich as NoSQL query system
	○ NoSQL:
		- You can store data in formats like key-value, document (JSON-like), column-family, or graph.
		- Built to scale horizontally easily (sharding across multiple servers is native).
		- you can query based on keys and nested keys (document), this supported in NoSQL databases like MongoDB
- how id constructed to each row inserted in distributed/horizontal-scaled DB like in NoSQL, how you guarantee that id is unique?
	○ classic auto increment id breaks, because ids may be redundant across machines.
	○ solution 1 is to make central id generator service
		- one small service is responsible only for generating ids, all app servers ask it for a new id.
		- downsides: 
			□ this service becomes a bottleneck, so if it goes down, writes stop
			□ another network overhead. 
	○ solution 2 is to generate Guid
		- it is a large identifier generated locally, often using randomness or a combination of time and machine specific data.
		- it's for example 128 bits in size, commonly represented as a 36 character string including separators.
		- downsides: 
			□ large size, it will take more extra space
			□ indexes will become slower
			□ ids are not ordered
	○ solution3 is using current time with something unique
		- for example: timestamp (you can use UTC to avoid clock skew) + machine id + counter
			□ time gives order, node id avoids cross server collision, sequence avoids same time collision
		- impact:
			□ ids are sortable
			□ good index performance
			□ no central service needed
	○ solution 4 is to give each server range of ids
	○ other solution is to let it to the DBMS itself like MongoDB …etc.
- servers >> datacenter >> availability zone >> region >> global
- what's the difference between load balancer and geo routing and DNS.
  ○ they operate at different layers and different decisions.
  ○ load balancer:
    - mainly decides which server handles the request
  ○ geo routing 
    - geo routing decides which region or endpoint IP the user should be sent to
  ○ DNS is like the internet’s phone book. Every website has an IP address
    - we are humans, and we remember names so DNS translates the human-friendly name into the computer-friendly IP address.
    - so when you type the url, then computer send to DNS server and replies with IP.
    - your browser connects to that Ip and loads the website.
    - DNS with geo routing enabled returns an IP address that already points to the chosen region.
	- same data center:
		○ All servers are in one physical building.
		○ prefered to be used when app is smaller or medium and users are mostly local, and  the cost may be low
		○ scaling works by adding a load balancer and more application servers in the same data center.
		○ network latency between servers is extremely low and usually negligible, user facing latency still depends on how far the user is from the data center.
		○ pros: very low network delay, simple architecture, easy database consistency.
		○ cons: the data center is a single point of failure, if the data center fails everything will goes down, user far away still get latency.
	- same region:
		○ you pick a region that is geographically closer to the majority of your users, for example in AWS you have 'us-east', 'us-west'  …etc.
		○ you can pick a region that are closer to your user application, deploy to multiple datacenter in same region.
		○ you are protected from single data center failures (SPOF), region wide failures are still possible but much rarer.
	- different region:
		○ you can deploy to different regions for example near to your users in middle east and to you users in Europe, USA …etc.
		○  gives you higher availability, This is true global scale.
		○ lower user latency for nearby users, higher availability and scalability, additional complexity due to data replication and legal requirements based on region you deploy on:
			- GDPR in EU, HIPAA … in USA
			- for example in EU, Explicit user consent required for cookies, tracking, data processing …etc., Often requires data to be stored in-region or at least comply with GDPR when transferring outside EU
			- the fines with this laws are very high, if you deployed to region and you broke the rules.
      	○ you should not rely on a single global primary database for all regions.
- core problem
  ○ When your system runs on more than one machine, failures and network delays are guaranteed
  ○ you cannot assume all machines see the same data, you cannot assume that the network is always reliable
  ○ CAP theorem explains the limits of distributed systems under these conditions.
- when a network partition happen you must choose consistency or availability, you cannot keep both.
  ○ Partition tolerance is not optional in real systems, it's mandatory
- Consistency (strong consistency)
  ○ means every successful read returns the most recent successful write
- Availability
  ○ Every request receives a response, without the guarantee that it contains the most recent write.
  ○ The system remains operational even if some nodes are down, The system does not refuse requests due to coordination or consistency checks.
- partition tolerance
  ○ means, the system continues to work even when the network breaks between machines.
  ○ like network link failure, or timeout between servers.
- CP
  ○ Consistency and Partition tolerance
  ○ If a network partition occurs, the system will sacrifice Availability to maintain data integrity.
  ○ The system may reject requests or time out if it cannot guarantee that it is returning the most recent write. Users may see errors (e.g., "Service Unavailable"), but they will never receive "stale" or incorrect data.
- AP
  ○ Availability and Partition tolerance
  ○ If a network partition occurs, the system will sacrifice strict Consistency to remain operational, Data may be stale temporarily (eventual consistency), but data syncs later, so Every request received by a non-failing node must result in a successful (non-error) response.
  ○ used with systems like social network, features like 'comments' 'likes' …etc.
- CA 
  ○ systems do not exist in real distributed systems.
	- CAP theorem means 
		○ When a partition happens, you must choose which property to sacrifice between consistency and availability.
		○ you choose which failure you prefer.
	- in interview keep in mind
		○ If your system runs on more than one machine, partition tolerance is mandatory.
		○ CA systems do not exist in real distributed systems, CA systems can exist only when there is no network partition.
		○ say for example 'My system prioritizes consistency over availability during network failures because ….'.
		○ Interviewers care about tradeoffs, don't say 'I choose AP', but say 'I choose AP because showing stale data for 5 seconds is acceptable for this product'